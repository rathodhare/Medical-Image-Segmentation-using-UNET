{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final - Assignment1-TF.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "edamUsKBq9bz"
      },
      "source": [
        "from keras import backend as K\n",
        "import sys\n",
        "import math\n",
        "from tqdm import tqdm\n",
        "from skimage.io import imread, imshow\n",
        "from skimage.transform import resize\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from skimage.exposure import equalize_hist\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "IMG_HEIGHT = 256\n",
        "IMG_WIDTH = 208\n",
        "IMG_CHANNEL = 1 \n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!pip install pydicom\n",
        "import pydicom\n",
        "e = 2.7182"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5wHOEGq7_4fY"
      },
      "source": [
        "def Transform_data_train(X,y):\n",
        "    args = dict(\n",
        "        rotation_range = 20,\n",
        "        horizontal_flip = True,\n",
        "        vertical_flip = True)\n",
        "    img_datagen = ImageDataGenerator(**args)\n",
        "    mask_datagen = ImageDataGenerator(**args)\n",
        "    X_gen = img_datagen.flow(X, y, batch_size=4)\n",
        "    # y_gen = mask_datagen.flow(y, batch_size=4)\n",
        "    # gen = zip(X_gen, y_gen)\n",
        "    return X_gen\n",
        "\n",
        "def Transform_data_val(X,y):\n",
        "    args = dict(\n",
        "        rotation_range = 20,\n",
        "        horizontal_flip = True,\n",
        "        vertical_flip = True)\n",
        "    img_datagen = ImageDataGenerator(**args)\n",
        "    mask_datagen = ImageDataGenerator(**args)\n",
        "\n",
        "    X_gen = img_datagen.flow(X, y, batch_size=1)\n",
        "    # y_gen = mask_datagen.flow(y, batch_size=1)\n",
        "    # gen = zip(X_gen, y_gen)\n",
        "    return X_gen"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZT5bHSWr1ln"
      },
      "source": [
        "import glob, os\n",
        "Icountour_Train = glob.glob('/content/drive/My Drive/RVData/unrar_files/TrainingSet/*-icontour-manual.txt')\n",
        "Ocountour_Train = glob.glob('/content/drive/My Drive/RVData/unrar_files/TrainingSet/*-ocontour-manual.txt')\n",
        "IMG_Train = []\n",
        "for i in range(0,len(Icountour_Train)):\n",
        "  IMG_Train.append(Icountour_Train[i][:63]+'.dcm')\n",
        "\n",
        "X_train = []\n",
        "y_train = []\n",
        "for i, filename in enumerate(IMG_Train):\n",
        "  img = pydicom.dcmread(IMG_Train[i]).pixel_array.astype(int)\n",
        "  img_shape = img.shape\n",
        "  masks = np.loadtxt(Ocountour_Train[i]).astype(int)\n",
        "  mask_img = np.zeros(img_shape, dtype = np.float32)\n",
        "  cv2.fillPoly(mask_img, pts = [masks], color = 1)\n",
        "  if img_shape == (216,IMG_HEIGHT):\n",
        "        img = np.transpose(img)\n",
        "        mask_img = np.transpose(mask_img)\n",
        "  img = img[:, 4:212]\n",
        "  mask_img = mask_img[:,4:212]\n",
        "  img = np.expand_dims(equalize_hist(image= img), axis = 2)\n",
        "  X_train.append(img)\n",
        "  mask_img = np.expand_dims(mask_img, axis = 2)\n",
        "  y_train.append(mask_img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3NF-1vwsBWD"
      },
      "source": [
        "X_val = np.array(X_train[200:], dtype = np.float32)\n",
        "y_val = np.array(y_train[200:], dtype = np.float32)\n",
        "X_train = np.array(X_train[:200], dtype = np.float32)\n",
        "y_train = np.array(y_train[:200], dtype = np.float32)\n",
        "Train_data = Transform_data_train(X_train, y_train)\n",
        "Val_data = Transform_data_val(X_val, y_val)\n",
        "# X_train, y_train = Transform_data_train(X_train, y_train)\n",
        "# X_val, y_val = Transform_data_val(X_val, y_val)\n",
        "# print(X_train)\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_val.shape)\n",
        "print(y_val.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5SN0fthu5a1"
      },
      "source": [
        "def SmoothDiceBCE_Loss(targets, inputs, eps = 1e-6):\n",
        "\tinputs = K.reshape(inputs, (K.shape(inputs)[0],-1))\n",
        "\ttargets = K.reshape(targets, (K.shape(targets)[0],-1))\n",
        "\tBCE = K.mean(K.binary_crossentropy(targets,inputs),axis = 1)\n",
        "\tintersection = K.sum(targets*inputs, axis = 1)\n",
        "\tDice_Loss = 1 - (2*intersection+eps)/(K.sum(targets, axis = 1) + K.sum(inputs, axis = 1) + eps)\n",
        "\tFinal = BCE + Dice_Loss\n",
        "\treturn Final\n",
        "\n",
        "def SmoothDiceBCEInvDice_Loss(targets, inputs, eps = 1e-6):\n",
        "\tinputs = K.reshape(inputs, (K.shape(inputs)[0],-1))\n",
        "\ttargets = K.reshape(targets, (K.shape(targets)[0],-1))\n",
        "\tBCE = K.mean(K.binary_crossentropy(targets,inputs),axis = 1)\n",
        "\tintersection = K.sum(targets*inputs, axis = 1)\n",
        "\tDice_Loss = 1 - (2*intersection+eps)/(K.sum(targets, axis = 1) + K.sum(inputs, axis = 1) + eps)\n",
        "\tInv_inputs = 1 - inputs\n",
        "\tInv_targets = 1 - targets\n",
        "\tInv_intersection = K.sum(Inv_targets*Inv_inputs, axis = 1)\n",
        "\tInv_Dice_Loss = 1 - (2*Inv_intersection+eps)/(K.sum(Inv_targets, axis = 1) + K.sum(Inv_inputs, axis = 1) + eps)\n",
        "\tFinal = BCE+Dice_Loss+Inv_Dice_Loss\n",
        "\treturn Final\n",
        "\n",
        "def Switching_Loss(targets, inputs, l = 0.75, t = 0.3, eps = 1e-6):\n",
        "\tinputs = K.reshape(inputs, (K.shape(inputs)[0],-1))\n",
        "\ttargets = K.reshape(targets, (K.shape(targets)[0],-1))\n",
        "\tbackground = 1 - K.mean(targets)\n",
        "\tif(background<t):\n",
        "\t\tl = 1-l\n",
        "\tBCE = K.mean(K.binary_crossentropy(targets, inputs), axis= 1)\n",
        "\tintersection = K.sum(targets*inputs, axis = 1)\n",
        "\tDice_Loss = 1 - (2*intersection+eps)/(K.sum(targets, axis = 1) + K.sum(inputs, axis = 1) + eps)\n",
        "\tInv_inputs = 1 - inputs\n",
        "\tInv_targets = 1 - targets\n",
        "\tInv_intersection = K.sum(Inv_targets*Inv_inputs, axis = 1)\n",
        "\tInv_Dice_Loss = 1 - (2*Inv_intersection+eps)/(K.sum(Inv_targets, axis = 1) + K.sum(Inv_inputs, axis = 1) + eps)\n",
        "\tFinal = BCE+l*Dice_Loss + (1-l)*Inv_Dice_Loss\n",
        "\treturn Final\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8oTy4qOTDv0r"
      },
      "source": [
        "#DICE_COEFF\n",
        "def dice_coef(y_true, y_pred, eps = 1e-6):\n",
        "    y_pred = K.round(y_pred)\n",
        "    intersection = K.sum(y_true*y_pred, axis = [1,2,3])\n",
        "    union = K.sum(y_true, axis = [1,2,3]) + K.sum(y_pred, axis = [1,2,3])\n",
        "    dice = K.mean((2*intersection + eps)/(union+eps), axis = 0)\n",
        "    return dice"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Wm-G4hdu7yD"
      },
      "source": [
        "#ARCHITECTURE GOES HERE\n",
        "from keras import layers, Input\n",
        "from keras import models, Model\n",
        "from keras import optimizers\n",
        "from keras.layers import Dense, Flatten, Activation, Dropout, MaxPooling2D, Conv2DTranspose, Conv2D, Concatenate\n",
        "from keras import regularizers\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "\n",
        "\n",
        "inputs = Input(shape=(IMG_HEIGHT,IMG_WIDTH,IMG_CHANNEL))\n",
        "s = tf.keras.layers.Lambda(lambda x: x/255)(inputs)\n",
        "x1 = Conv2D(16, (3,3), activation='relu', padding='same')(s)\n",
        "x1 = Conv2D(16, (3,3), activation='relu', padding='same')(BatchNormalization()(x1))\n",
        "x1_m = MaxPooling2D((2,2))(BatchNormalization()(x1))\n",
        "\n",
        "x2 = Conv2D(32, (3,3), activation='relu', padding='same')(x1_m)\n",
        "x2 = Conv2D(32, (3,3), activation='relu', padding='same')(BatchNormalization()(x2))\n",
        "x2_m = MaxPooling2D((2,2))(BatchNormalization()(x2))\n",
        "\n",
        "x3 = Conv2D(64, (3,3), activation='relu', padding='same')(x2_m)\n",
        "x3 = Conv2D(64, (3,3), activation='relu', padding='same')(BatchNormalization()(x3))\n",
        "x3_m = MaxPooling2D((2,2))(BatchNormalization()(x3))\n",
        "\n",
        "x4 = Conv2D(128, (3,3), activation='relu', padding='same')(x3_m)\n",
        "x4 = Conv2D(128, (3,3), activation='relu', padding='same')(BatchNormalization()(x4))\n",
        "x4_m = MaxPooling2D((2,2))(BatchNormalization()(x4))\n",
        "\n",
        "x5 = Conv2D(256, (3,3), activation='relu', padding='same')(x4_m)\n",
        "x5 = Conv2D(256, (3,3), activation='relu', padding='same')(BatchNormalization()(x5))\n",
        "x5_u = Conv2DTranspose(512, (3,3), strides=(2,2), padding='same')(BatchNormalization()(x5))\n",
        "\n",
        "x6 = Concatenate()([x4,x5_u])\n",
        "x6 = Conv2D(128, (3,3), activation='relu', padding='same')(x6)\n",
        "x6 = Conv2D(128, (3,3), activation='relu', padding='same')(BatchNormalization()(x6))\n",
        "x6_u = Conv2DTranspose(64, (3,3), strides=(2,2), padding='same')(BatchNormalization()(x6))\n",
        "\n",
        "x7 = Concatenate()([x3,x6_u])\n",
        "x7 = Conv2D(64, (3,3), activation='relu', padding='same')(x7)\n",
        "x7 = Conv2D(64, (3,3), activation='relu', padding='same')(BatchNormalization()(x7))\n",
        "x7_u = Conv2DTranspose(32, (3,3), strides=(2,2), padding='same')(BatchNormalization()(x7))\n",
        "\n",
        "x8 = Concatenate()([x2,x7_u])\n",
        "x8 = Conv2D(32, (3,3), activation='relu', padding='same')(x8)\n",
        "x8 = Conv2D(32, (3,3), activation='relu', padding='same')(BatchNormalization()(x8))\n",
        "x8_u = Conv2DTranspose(16, (3,3), strides=(2,2), padding='same')(BatchNormalization()(x8))\n",
        "\n",
        "x9 = Concatenate()([x1,x8_u])\n",
        "x9 = Conv2D(16, (3,3), activation='relu', padding='same')(x9)\n",
        "x9 = Conv2D(16, (3,3), activation='relu', padding='same')(BatchNormalization()(x9))\n",
        "\n",
        "# outputs = Conv2D(1, (1,1), activation='sigmoid', padding='same')(c9)\n",
        "outputs = Conv2D(1, (1,1), activation='sigmoid')(BatchNormalization()(x9))\n",
        "model = Model(inputs=[inputs], outputs=[outputs], name=\"UNET_baseline\")\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xF-gSOlEqTPE"
      },
      "source": [
        "def step_decay(epoch):\n",
        "   initial_lrate = 0.1\n",
        "   drop = 0.5\n",
        "   epochs_drop = 10.0\n",
        "   lrate = initial_lrate * math.pow(drop,  \n",
        "           math.floor((1+epoch)/epochs_drop))\n",
        "   return lrate\n",
        "\n",
        "lrate = tf.keras.callbacks.LearningRateScheduler(step_decay)\n",
        "learning_rate = 0.1\n",
        "decay_rate = learning_rate / 150\n",
        "momentum = 0.8\n",
        "sgd = tf.keras.optimizers.SGD(lr=learning_rate, momentum=momentum, decay=decay_rate, nesterov=False)\n",
        "model.compile(loss=Switching_Loss, optimizer=optimizers.Adam(lr=1e-3), metrics=[dice_coef])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bxnH5VEmP3Jd"
      },
      "source": [
        "from keras.callbacks  import ReduceLROnPlateau\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.2, patience=5)\n",
        "checkpoint = ModelCheckpoint('best.h5', verbose=1, monitor='val_acc',save_best_only=True)\n",
        "\n",
        "history = model.fit(X_gen, y_train, batch_size = 4, epochs = 200, callbacks=[checkpoint,lrate], validation_data = (X_val, y_val), shuffle= False)\n",
        "# history = model.fit(Train_data, steps_per_epoch = 50, epochs = 200, callbacks=[checkpoint, learning_rate], validation_data = Val_data, validation_steps = 43)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lkIqosWER7gB"
      },
      "source": [
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['loss'][1:])\n",
        "plt.plot(history.history['val_loss'][1:])\n",
        "plt.legend(['Training loss', 'Validation loss'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gfx7xBGdSXfr"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "output = model.predict(X_val)\n",
        "imshow(output[0,:,:,0], cmap = 'gray')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emGrYgMSzE-_"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "output = model.predict(X_train)\n",
        "imshow(output[1,:,:,0], cmap = 'gray')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AIAPJAiAzJrU"
      },
      "source": [
        "imshow(y_val[0,:,:,0], cmap = 'gray')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTzzBzK2ziYp"
      },
      "source": [
        "imshow(y_train[0,:,:,0], cmap = 'gray')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}